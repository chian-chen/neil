{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import cv2\n",
    "import os\n",
    "from scipy.signal import medfilt2d\n",
    "from scipy.ndimage import laplace, convolve\n",
    "from scipy.signal import convolve2d\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from numpy.lib.stride_tricks import sliding_window_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(errors):\n",
    "# some index should by -1, stupid GPT :(\n",
    "    errors = np.sort(errors)\n",
    "    n = len(errors)\n",
    "    f05 = errors[int(np.floor(0.5 * n)) - 1]\n",
    "    f025 = errors[int(np.floor(0.25 * n)) - 1]\n",
    "    f075 = errors[int(np.floor(0.75 * n)) - 1]\n",
    "    med = np.median(errors)\n",
    "    men = np.mean(errors)\n",
    "    trimean = 0.25 * (f025 + 2 * f05 + f075)\n",
    "    bst25 = np.mean(errors[:int(np.floor(0.25 * n))])\n",
    "    wst25 = np.mean(errors[int(np.floor(0.75 * n) - 1) :])\n",
    "\n",
    "    return men, med, trimean, bst25, wst25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angerr2(l1, l2):\n",
    "\n",
    "    l1 = l1 / (np.linalg.norm(l1) + 1e-12)\n",
    "    l2 = l2 / (np.linalg.norm(l2) + 1e-12)\n",
    "    rec = np.degrees(np.arccos(np.clip(np.sum(l1 * l2), -1, 1)))\n",
    "    LL = l2 / (l1 + 1e-12)\n",
    "    rep = np.degrees(np.arccos(np.dot(LL, np.ones(3)) /\n",
    "                                 (np.sqrt(3) * np.sqrt(np.sum(LL ** 2)))))\n",
    "    return rec, rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_border(inp, width, method=1):\n",
    "    temp = np.ones_like(inp)\n",
    "    rr, cc = inp.shape\n",
    "    y, x = np.ogrid[:rr, :cc]\n",
    "    temp *= ((x < (cc - width)) & (x + 1 > width))\n",
    "    temp *= ((y < (rr - width)) & (y + 1 > width))\n",
    "    out = temp * inp\n",
    "    if method == 1:\n",
    "        if np.sum(temp) != 0:\n",
    "            avg_val = np.sum(out) / np.sum(temp)\n",
    "        else:\n",
    "            avg_val = 0\n",
    "        out = out + avg_val * (np.ones_like(inp) - temp)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilation33(inp, it=1):\n",
    "    inp = np.array(inp)\n",
    "    hh, ll = inp.shape\n",
    "    \n",
    "    for _ in range(it):\n",
    "\n",
    "        channel0 = np.vstack((inp[1:, :], inp[-1:, :]))\n",
    "        channel1 = inp.copy()\n",
    "        channel2 = np.vstack((inp[0:1, :], inp[:-1, :]))\n",
    "\n",
    "        temp = np.stack((channel0, channel1, channel2), axis=2)\n",
    "        out2 = np.max(temp, axis=2)\n",
    "        \n",
    "\n",
    "        channel0_h = np.hstack((out2[:, 1:], out2[:, -1:]))\n",
    "        channel1_h = out2.copy()\n",
    "        channel2_h = np.hstack((out2[:, 0:1], out2[:, :ll-1]))\n",
    "        \n",
    "        temp2 = np.stack((channel0_h, channel1_h, channel2_h), axis=2)\n",
    "        inp = np.max(temp2, axis=2)\n",
    "    \n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updated_saliency_map(sRGBImage, VarThreshold, ColorThreshold):\n",
    "    # Compute the logarithm of each color channel\n",
    "    r_ln = np.log(sRGBImage[:, :, 0] + 1)\n",
    "    g_ln = np.log(sRGBImage[:, :, 1] + 1)\n",
    "    b_ln = np.log(sRGBImage[:, :, 2] + 1)\n",
    "\n",
    "    # Compute the variance map along the third dimension (channels)\n",
    "    stacked = np.stack((r_ln, g_ln, b_ln), axis=2)\n",
    "    variance_map = np.var(stacked, axis=2, ddof=1)\n",
    "    \n",
    "    # Create an initial saliency map: pixels with variance > VarThreshold are set to 1\n",
    "    updated_saliencyMap = np.zeros_like(variance_map)\n",
    "    updated_saliencyMap[variance_map > VarThreshold] = 1\n",
    "    \n",
    "    # Apply a median filter with an 11x11 kernel\n",
    "    updated_saliencyMap = medfilt2d(updated_saliencyMap, kernel_size=11)\n",
    "    \n",
    "    # Compute the means for each channel and the minimum mean\n",
    "    Mr = np.mean(r_ln, axis=0)\n",
    "    Mg = np.mean(g_ln, axis=0)\n",
    "    Mb = np.mean(b_ln, axis=0)\n",
    "    Minimum = np.min(np.concatenate([Mr, Mg, Mb]))\n",
    "    \n",
    "    # Compute absolute differences from the mean for each channel\n",
    "    Xr = np.abs(r_ln - Mr)\n",
    "    Xg = np.abs(g_ln - Mg)\n",
    "    Xb = np.abs(b_ln - Mb)\n",
    "        \n",
    "    # Determine a threshold based on the minimum mean and ColorThreshold factor\n",
    "    threshold = ColorThreshold * Minimum\n",
    "    \n",
    "    # Compute a difference map taking the maximum difference across channels\n",
    "    difference_map = np.maximum(np.maximum(Xr, Xg), Xb)\n",
    "    \n",
    "    # Identify pixels considered \"not important\"\n",
    "    not_important_mask = difference_map > threshold\n",
    "\n",
    "    # Zero out not-important pixels in the saliency map\n",
    "    updated_saliencyMap2 = updated_saliencyMap.copy()\n",
    "    updated_saliencyMap2[not_important_mask] = 0\n",
    "    \n",
    "    return updated_saliencyMap2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_edge_confidence(image, mask, bitDepth):\n",
    "    # Scale image channels according to bitDepth\n",
    "    scale = 2 ** bitDepth\n",
    "    R = image[:, :, 0] / scale\n",
    "    G = image[:, :, 1] / scale\n",
    "    B = image[:, :, 2] / scale\n",
    "    \n",
    "    # Compute the average intensity (OW)\n",
    "    OW = (R + G + B) / 3.0\n",
    "    OW = OW * mask  # apply the mask\n",
    "    \n",
    "    # Extract non-zero elements for skewness and mean calculation\n",
    "    nonzero = OW[OW != 0]\n",
    "    if nonzero.size == 0:\n",
    "        # Avoid division by zero if mask removes all pixels\n",
    "        OWskew = 0\n",
    "        m = 1.0\n",
    "    else:\n",
    "        OWskew = skew(nonzero)\n",
    "        m = np.mean(nonzero)\n",
    "    \n",
    "    # Determine exponent E based on the skewness\n",
    "    if OWskew > 1.5:\n",
    "        E = 1.0\n",
    "    elif OWskew > 0.2:\n",
    "        E = 2.0\n",
    "    else:\n",
    "        E = 4.0\n",
    "    \n",
    "    # Compute the edge weights\n",
    "    edge_weights = 1 - np.exp(-((OW / m) ** E))\n",
    "    edge_weights[edge_weights < 0.90] = 0\n",
    "    \n",
    "    # Recompute if all values are zero (as in the MATLAB code)\n",
    "    if np.sum(edge_weights) == 0:\n",
    "        edge_weights = 1 - np.exp(-((OW / m) ** E))\n",
    "    \n",
    "    return edge_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_derivative(channel, order, sigma):\n",
    "    # Determine kernel size: ceil(6*sigma); make it odd if necessary.\n",
    "    kernel_size = int(np.ceil(6 * sigma))\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1\n",
    "\n",
    "    # Create a Gaussian kernel using OpenCV. cv2.getGaussianKernel returns a column vector.\n",
    "    k = cv2.getGaussianKernel(kernel_size, sigma)\n",
    "    G = k * k.T  # Create 2D kernel by outer product.\n",
    "    \n",
    "    # Smooth the channel using cv2.filter2D with border replication.\n",
    "    smoothed = cv2.filter2D(channel, -1, G, borderType=cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    if order == 1:\n",
    "        grad_y, grad_x = np.gradient(smoothed)\n",
    "        derivative = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    else:\n",
    "        derivative = np.abs(laplace(smoothed))\n",
    "        \n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_illuminant_pixelwise(image, order, p, sigma, mask):\n",
    "    # Convert image to double if necessary (im2double equivalent)\n",
    "    if image.dtype != np.float64:\n",
    "        image = image.astype(np.float64) / 255.0\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    # Compute derivatives for each channel\n",
    "    derivatives = np.zeros_like(image)\n",
    "    for c in range(3):\n",
    "        derivatives[:, :, c] = compute_derivative(image[:, :, c], order, sigma)\n",
    "    \n",
    "    # Compute edge confidence measures\n",
    "    bitDepth = 14\n",
    "    edge_weights = compute_edge_confidence(image, mask, bitDepth)\n",
    "    \n",
    "    # Local processing parameters\n",
    "    window_size = 3\n",
    "    pad_size = window_size // 2\n",
    "    # Pad derivatives and edge_weights using replicate padding\n",
    "    padded_derivatives = np.pad(derivatives, ((pad_size, pad_size), (pad_size, pad_size), (0, 0)), mode='edge')\n",
    "    # Note: padded_weights is computed but not used; we use the original edge_weights.\n",
    "    \n",
    "    numerator = np.zeros(3)\n",
    "    denominator = np.zeros(3)\n",
    "    \n",
    "    # Process each pixel with edge confidence weighting\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            for c in range(3):\n",
    "                window = padded_derivatives[y:y+window_size, x:x+window_size, c]\n",
    "                max_val = np.max(window)\n",
    "                if max_val > 0:\n",
    "                    nonzero_elements = window[window != 0]\n",
    "                    center_val2 = np.mean(nonzero_elements) if nonzero_elements.size > 0 else 0\n",
    "                    center_weight = edge_weights[y, x]\n",
    "                    norm_center = center_val2 / max_val\n",
    "                    weighted_val = center_val2 * center_weight\n",
    "                    weighted_norm = norm_center * center_weight\n",
    "                    numerator[c] += np.abs(weighted_val)**p\n",
    "                    denominator[c] += np.abs(weighted_norm)**p\n",
    "    \n",
    "    illuminant = np.zeros(3)\n",
    "    for c in range(3):\n",
    "        if denominator[c] > 0:\n",
    "            illuminant[c] = (numerator[c] / denominator[c]) ** (1/p)\n",
    "    \n",
    "    # Normalize the illuminant vector\n",
    "    norm_val = np.linalg.norm(illuminant)\n",
    "    if norm_val > 0:\n",
    "        illuminant = illuminant / norm_val\n",
    "    return illuminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accelerated version of the above function\n",
    "def estimate_illuminant_pixelwise_accelerated(image, order, p, sigma, mask):\n",
    "    # Convert image to float64 (im2double equivalent)\n",
    "    if image.dtype != np.float64:\n",
    "        image = image.astype(np.float64) / 255.0\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    # Compute derivatives for each channel\n",
    "    derivatives = np.empty_like(image)\n",
    "    for c in range(3):\n",
    "        derivatives[..., c] = compute_derivative(image[..., c], order, sigma)\n",
    "\n",
    "    # Compute edge confidence measures\n",
    "    bitDepth = 14\n",
    "    edge_weights = compute_edge_confidence(image, mask, bitDepth)\n",
    "\n",
    "    # Local processing parameters\n",
    "    window_size = 3\n",
    "    pad_size = window_size // 2\n",
    "    # Replicate padding (\"edge\" mode)\n",
    "    padded_derivatives = np.pad(derivatives, ((pad_size, pad_size), (pad_size, pad_size), (0, 0)), mode='edge')\n",
    "\n",
    "    numerator = np.zeros(3)\n",
    "    denominator = np.zeros(3)\n",
    "\n",
    "    # Process each channel with vectorized sliding window operations\n",
    "    for c in range(3):\n",
    "        # Extract sliding windows for the current channel.\n",
    "        # Resulting shape is (h, w, window_size, window_size)\n",
    "        windows = sliding_window_view(padded_derivatives[:, :, c], (window_size, window_size))\n",
    "        \n",
    "        # Compute maximum value in each window\n",
    "        max_vals = np.max(windows, axis=(-1, -2))\n",
    "        \n",
    "        # Compute mean of nonzero elements in each window:\n",
    "        nonzero_mask = windows != 0\n",
    "        # Sum only the nonzero elements\n",
    "        sum_nonzero = np.sum(np.where(nonzero_mask, windows, 0), axis=(-1, -2))\n",
    "        # Count of nonzero elements in each window\n",
    "        count_nonzero = np.sum(nonzero_mask, axis=(-1, -2))\n",
    "        # Compute mean safely; if no nonzero elements, mean is set to 0.\n",
    "        mean_vals = np.divide(sum_nonzero, count_nonzero, out=np.zeros_like(sum_nonzero), where=(count_nonzero != 0))\n",
    "        \n",
    "        # Only consider pixels where the maximum is positive\n",
    "        valid = max_vals > 0\n",
    "        \n",
    "        # Edge weight for each pixel (broadcast over the h x w grid)\n",
    "        center_weight = edge_weights\n",
    "        # Compute the normalized center value where valid\n",
    "        norm_center = np.zeros_like(mean_vals)\n",
    "        norm_center[valid] = mean_vals[valid] / max_vals[valid]\n",
    "        \n",
    "        # Compute weighted values using the edge confidence\n",
    "        weighted_val = mean_vals * center_weight\n",
    "        weighted_norm = norm_center * center_weight\n",
    "        \n",
    "        # Accumulate numerator and denominator over valid pixels only\n",
    "        numerator[c] = np.sum(np.abs(weighted_val[valid]) ** p)\n",
    "        denominator[c] = np.sum(np.abs(weighted_norm[valid]) ** p)\n",
    "\n",
    "    # Compute per-channel illuminant estimate\n",
    "    illuminant = np.zeros(3)\n",
    "    for c in range(3):\n",
    "        if denominator[c] > 0:\n",
    "            illuminant[c] = (numerator[c] / denominator[c]) ** (1/p)\n",
    "\n",
    "    # Normalize the illuminant vector\n",
    "    norm_val = np.linalg.norm(illuminant)\n",
    "    if norm_val > 0:\n",
    "        illuminant = illuminant / norm_val\n",
    "\n",
    "    return illuminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_gauss(img, sigma):\n",
    "    GaussianDieOff = 1e-6\n",
    "    # Possible widths from 1 to 50.\n",
    "    pw = np.arange(1, 51)  # equivalent to 1:50 in MATLAB\n",
    "    ssq = sigma ** 2\n",
    "    exp_vals = np.exp(-(pw**2) / (2 * ssq))\n",
    "    valid = np.where(exp_vals > GaussianDieOff)[0]\n",
    "    if valid.size > 0:\n",
    "        # valid indices start at 0, so add 1 to match MATLAB indexing range.\n",
    "        width = valid[-1] + 1\n",
    "    else:\n",
    "        width = 1  # user entered a really small sigma\n",
    "    \n",
    "    # Create meshgrid for kernel indices from -width to width.\n",
    "    xs = np.arange(-width, width+1)\n",
    "    ys = np.arange(-width, width+1)\n",
    "    x, y = np.meshgrid(xs, ys)\n",
    "    \n",
    "    # Construct the derivative Gaussian filter.\n",
    "    dgau2D = -x * np.exp(-(x**2 + y**2) / (2 * ssq)) / (np.pi * ssq)\n",
    "    \n",
    "    # Convolve the image with the kernel and its transpose.\n",
    "    ax = convolve(img, dgau2D, mode='nearest')\n",
    "    ay = convolve(img, dgau2D.T, mode='nearest')\n",
    "    \n",
    "    # Compute the magnitude.\n",
    "    mag = np.sqrt(ax**2 + ay**2)\n",
    "    return mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normr(data):\n",
    "    norms = np.linalg.norm(data, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = np.finfo(float).eps\n",
    "    return data / norms\n",
    "\n",
    "def matlab_prctile(data, percentage):\n",
    "    data_sorted = np.sort(data) \n",
    "    n = len(data_sorted)\n",
    "    p = percentage / 100.0\n",
    "    rank = p * (n - 1) + 1\n",
    "    k = int(np.floor(rank))\n",
    "    d = rank - k\n",
    "    if k - 1 < 0:\n",
    "        return data_sorted[0]\n",
    "    elif k >= n:\n",
    "        return data_sorted[-1]\n",
    "    else:\n",
    "        return data_sorted[k - 1] + d * (data_sorted[k] - data_sorted[k - 1])\n",
    "\n",
    "def gray_index_angular(img, mask, sigma, percentage):\n",
    "\n",
    "    eps_val = np.finfo(float).eps\n",
    "    rr, cc, dd = img.shape\n",
    "    \n",
    "    # Separate the color channels (MATLAB is 1-indexed; Python is 0-indexed)\n",
    "    R = img[:, :, 0].copy()\n",
    "    G = img[:, :, 1].copy()\n",
    "    B = img[:, :, 2].copy()\n",
    "    \n",
    "    # Replace zeros with eps\n",
    "    R[R == 0] = eps_val\n",
    "    G[G == 0] = eps_val\n",
    "    B[B == 0] = eps_val\n",
    "    \n",
    "    # Compute the Gaussian derivative magnitude of the logarithm of each channel.\n",
    "    Mr = deriv_gauss(np.log(R), sigma)\n",
    "    Mg = deriv_gauss(np.log(G), sigma)\n",
    "    Mb = deriv_gauss(np.log(B), sigma)\n",
    "    \n",
    "    # Create a data matrix (each row corresponds to a pixel, each column a channel)\n",
    "    data = np.column_stack((Mr.ravel(order='F'), Mg.ravel(order='F'), Mb.ravel(order='F'))).astype(np.float64)\n",
    "\n",
    "    \n",
    "    # Replace zeros in each channel (column) with eps\n",
    "    data[data[:, 0] == 0, 0] = eps_val\n",
    "    data[data[:, 1] == 0, 1] = eps_val\n",
    "    data[data[:, 2] == 0, 2] = eps_val\n",
    "    \n",
    "    # Row-normalize the data\n",
    "    data_normed = normr(data)\n",
    "    gt1 = normr(np.ones_like(data))\n",
    "    \n",
    "    dot_product = np.sum(data_normed * gt1, axis=1)\n",
    "    dot_product = np.clip(dot_product, -1, 1)\n",
    "    angular_error = np.arccos(dot_product)\n",
    "    \n",
    "    # Reshape the angular error into the image shape.\n",
    "    Greyidx_angular = angular_error.reshape((rr, cc), order='F').astype(np.float64)\n",
    "    \n",
    "    # Normalize Greyidx_angular to get Greyidx.\n",
    "    max_val = np.max(Greyidx_angular)\n",
    "    Greyidx = Greyidx_angular / (max_val + eps_val)\n",
    "    \n",
    "    # For pixels where all derivative responses are almost zero, set to max.\n",
    "    condition = (Mr < eps_val) & (Mg < eps_val) & (Mb < eps_val)\n",
    "    Greyidx[condition] = np.max(Greyidx)\n",
    "    Greyidx_angular[condition] = np.max(Greyidx_angular)\n",
    "    \n",
    "    # Create a 7x7 averaging kernel and apply circular filtering.\n",
    "    kernel = np.ones((7, 7), dtype=np.float64) / 49.0\n",
    "    Greyidx = convolve2d(Greyidx, kernel, mode='same', boundary='wrap')\n",
    "    Greyidx_angular = convolve2d(Greyidx_angular, kernel, mode='same', boundary='wrap')\n",
    "    \n",
    "    # If a mask is provided, force the angular index to its maximum where mask is true.\n",
    "    if mask is not None and mask.size > 0:\n",
    "        Greyidx_angular[mask.astype(bool)] = np.max(Greyidx_angular)\n",
    "    \n",
    "    # Determine the threshold based on the given percentile.\n",
    "    threshold = np.percentile(Greyidx_angular.ravel(order='F'), percentage, method='linear')\n",
    "\n",
    "    binary_mask = np.zeros_like(Greyidx_angular).astype(np.float64)\n",
    "    binary_mask[Greyidx_angular <= threshold] = 1\n",
    "    \n",
    "    return binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imresize_nearest(img, scale):\n",
    "\n",
    "    in_h, in_w = img.shape[:2]\n",
    "    out_h = int(np.round(in_h * scale))\n",
    "    out_w = int(np.round(in_w * scale))\n",
    "    \n",
    "    row_indices = np.clip(np.round((np.arange(out_h) + 0.5) / scale - 0.5).astype(int), 0, in_h - 1)\n",
    "    col_indices = np.clip(np.round((np.arange(out_w) + 0.5) / scale - 0.5).astype(int), 0, in_w - 1)\n",
    "    \n",
    "    if img.ndim == 3:\n",
    "        resized = img[row_indices[:, np.newaxis], col_indices, :]\n",
    "    else:\n",
    "        resized = img[row_indices[:, np.newaxis], col_indices]\n",
    "    \n",
    "    return resized\n",
    "\n",
    "def save_arrays_to_single_csv(array1, array2, filename=\"output.csv\"):\n",
    "    max_len = max(len(array1), len(array2))\n",
    "    \n",
    "    array1 = array1.flatten()\n",
    "    array2 = array2.flatten()\n",
    "    \n",
    "    array1 = np.pad(array1, (0, max_len - len(array1)), constant_values=np.nan)\n",
    "    array2 = np.pad(array2, (0, max_len - len(array2)), constant_values=np.nan)\n",
    "\n",
    "    df = pd.DataFrame({\"Perf\": array1, \"Perf_rep\": array2})\n",
    "\n",
    "    df.to_csv(filename, index=False, float_format=\"%.6f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1/513...\n",
      "Image 1: arr = 2.247135845487567, arr_rep = 4.577136343536422\n",
      "Processing image 2/513...\n",
      "Image 2: arr = 1.3048056308442486, arr_rep = 1.2400385635532754\n",
      "Processing image 3/513...\n",
      "Image 3: arr = 2.3706185897526404, arr_rep = 5.443484905228065\n",
      "Processing image 4/513...\n",
      "Image 4: arr = 0.23880914159789196, arr_rep = 0.4746624742402811\n",
      "Processing image 5/513...\n",
      "Image 5: arr = 8.158314418126386, arr_rep = 15.338554327718716\n",
      "Processing image 6/513...\n",
      "Image 6: arr = 4.284421539007811, arr_rep = 6.621144433691123\n",
      "Processing image 7/513...\n",
      "Image 7: arr = 4.663009787070876, arr_rep = 5.373250171276273\n",
      "Processing image 8/513...\n",
      "Image 8: arr = 9.973692007125466, arr_rep = 13.652785422569117\n",
      "Processing image 9/513...\n",
      "Image 9: arr = 2.0253370470272642, arr_rep = 2.78745849527705\n",
      "Processing image 10/513...\n",
      "Image 10: arr = 7.071092332451867, arr_rep = 8.964430096497766\n",
      "Processing image 11/513...\n",
      "Image 11: arr = 7.570258671410717, arr_rep = 10.543801366423287\n",
      "Processing image 12/513...\n",
      "Image 12: arr = 2.045542423892885, arr_rep = 3.0478015408929746\n",
      "Processing image 13/513...\n",
      "Image 13: arr = 1.5328073880639963, arr_rep = 1.7851241991800466\n",
      "Processing image 14/513...\n",
      "Image 14: arr = 10.492496229876467, arr_rep = 15.05207738994149\n",
      "Processing image 15/513...\n",
      "Image 15: arr = 1.9041530758541925, arr_rep = 2.8541164166305144\n",
      "Processing image 16/513...\n",
      "Image 16: arr = 3.3406788855796923, arr_rep = 5.022426065767976\n",
      "Processing image 17/513...\n",
      "Image 17: arr = 3.086743804828971, arr_rep = 4.146987246186499\n",
      "Processing image 18/513...\n",
      "Image 18: arr = 4.78291874136204, arr_rep = 5.806454210190572\n",
      "Processing image 19/513...\n",
      "Image 19: arr = 4.523877762454218, arr_rep = 6.376396683083876\n",
      "Processing image 20/513...\n",
      "Image 20: arr = 3.0268388608998076, arr_rep = 3.740715330901601\n",
      "Processing image 21/513...\n",
      "Image 21: arr = 2.354798166043173, arr_rep = 3.6238793521088386\n",
      "Processing image 22/513...\n",
      "Image 22: arr = 7.850262055346977, arr_rep = 9.39682838026225\n",
      "Processing image 23/513...\n",
      "Image 23: arr = 1.5138496680258915, arr_rep = 1.5446788463878847\n",
      "Processing image 24/513...\n",
      "Image 24: arr = 2.000660870446219, arr_rep = 1.8362465469655045\n",
      "Processing image 25/513...\n",
      "Image 25: arr = 3.114842324320196, arr_rep = 3.7896965979958503\n",
      "Processing image 26/513...\n",
      "Image 26: arr = 2.5335373793007383, arr_rep = 3.7935927513032475\n",
      "Processing image 27/513...\n",
      "Image 27: arr = 0.7188914016561437, arr_rep = 1.1535881675024808\n",
      "Processing image 28/513...\n",
      "Image 28: arr = 1.6096988280572648, arr_rep = 2.1882842969164313\n",
      "Processing image 29/513...\n",
      "Image 29: arr = 0.12767289614830432, arr_rep = 0.1921748574386145\n",
      "Processing image 30/513...\n",
      "Image 30: arr = 8.464399190669035, arr_rep = 12.071245005344608\n",
      "Processing image 31/513...\n",
      "Image 31: arr = 1.9267430517860866, arr_rep = 2.329075718814884\n",
      "Processing image 32/513...\n",
      "Image 32: arr = 1.4139142142568266, arr_rep = 1.3541076372699583\n",
      "Processing image 33/513...\n",
      "Image 33: arr = 1.1299194417314238, arr_rep = 1.270865144697408\n",
      "Processing image 34/513...\n",
      "Image 34: arr = 1.6853078409852924, arr_rep = 2.0547388352442115\n",
      "Processing image 35/513...\n",
      "Image 35: arr = 0.8792932830776545, arr_rep = 0.9909887894787295\n",
      "Processing image 36/513...\n",
      "Image 36: arr = 3.9538253168569244, arr_rep = 5.022691323539506\n",
      "Processing image 37/513...\n",
      "Image 37: arr = 0.6789214285492992, arr_rep = 1.511286469830009\n",
      "Processing image 38/513...\n",
      "Image 38: arr = 2.010357525537288, arr_rep = 5.015276106028253\n",
      "Processing image 39/513...\n",
      "Image 39: arr = 2.7173191383133473, arr_rep = 6.575029327622288\n",
      "Processing image 40/513...\n",
      "Image 40: arr = 18.46208676372186, arr_rep = 26.78564132123961\n",
      "Processing image 41/513...\n",
      "Image 41: arr = 1.0619666129746415, arr_rep = 1.4686606359067884\n",
      "Processing image 42/513...\n",
      "Image 42: arr = 1.536668718195418, arr_rep = 4.180237979987565\n",
      "Processing image 43/513...\n",
      "Image 43: arr = 2.218093440545212, arr_rep = 4.633142846318997\n",
      "Processing image 44/513...\n",
      "Image 44: arr = 1.0341891496959394, arr_rep = 1.8316828076947413\n",
      "Processing image 45/513...\n",
      "Image 45: arr = 6.276498530379954, arr_rep = 9.339526415774653\n",
      "Processing image 46/513...\n",
      "Image 46: arr = 1.9361492178794562, arr_rep = 3.0031220143706268\n",
      "Processing image 47/513...\n",
      "Image 47: arr = 14.767425215321412, arr_rep = 15.03111454746683\n",
      "Processing image 48/513...\n",
      "Image 48: arr = 0.6407110483291693, arr_rep = 0.8792007294055718\n",
      "Processing image 49/513...\n",
      "Image 49: arr = 16.131922189034395, arr_rep = 19.907937097610255\n",
      "Processing image 50/513...\n",
      "Image 50: arr = 3.988544154314208, arr_rep = 4.919190149699251\n",
      "Processing image 51/513...\n",
      "Image 51: arr = 6.061420473328696, arr_rep = 7.661711819047503\n",
      "Processing image 52/513...\n",
      "Image 52: arr = 1.6225088652886255, arr_rep = 2.382232266825463\n",
      "Processing image 53/513...\n",
      "Image 53: arr = 1.4347375641211377, arr_rep = 2.468657586324908\n",
      "Processing image 54/513...\n",
      "Image 54: arr = 9.954219047178034, arr_rep = 12.060834530506668\n",
      "Processing image 55/513...\n",
      "Image 55: arr = 6.385374447663594, arr_rep = 7.6722809714969396\n",
      "Processing image 56/513...\n",
      "Image 56: arr = 1.7203279092887516, arr_rep = 2.1496188945495627\n",
      "Processing image 57/513...\n",
      "Image 57: arr = 4.836399286522116, arr_rep = 5.175148759640724\n",
      "Processing image 58/513...\n",
      "Image 58: arr = 0.9648080964542789, arr_rep = 1.184609139814195\n",
      "Processing image 59/513...\n",
      "Image 59: arr = 4.3622234310416905, arr_rep = 4.492456817359254\n",
      "Processing image 60/513...\n",
      "Image 60: arr = 3.3225813165989524, arr_rep = 4.245730320814323\n",
      "Processing image 61/513...\n",
      "Image 61: arr = 4.681511079411643, arr_rep = 5.925106344376861\n",
      "Processing image 62/513...\n",
      "Image 62: arr = 2.009451394725486, arr_rep = 2.3506074290328205\n",
      "Processing image 63/513...\n",
      "Image 63: arr = 0.3724505334237954, arr_rep = 0.43185690321968656\n",
      "Processing image 64/513...\n",
      "Image 64: arr = 3.450362992907123, arr_rep = 4.174133867254075\n",
      "Processing image 65/513...\n",
      "Image 65: arr = 3.868257451020545, arr_rep = 4.96974262632653\n",
      "Processing image 66/513...\n",
      "Image 66: arr = 2.1536019850621413, arr_rep = 2.286045560270892\n",
      "Processing image 67/513...\n",
      "Image 67: arr = 5.356048657065279, arr_rep = 6.809743949605962\n",
      "Processing image 68/513...\n",
      "Image 68: arr = 1.0626214713246913, arr_rep = 1.2541961540226325\n",
      "Processing image 69/513...\n",
      "Image 69: arr = 3.250483560403816, arr_rep = 3.6762620192332895\n",
      "Processing image 70/513...\n",
      "Image 70: arr = 3.2240683883749264, arr_rep = 3.771523767888604\n",
      "Processing image 71/513...\n",
      "Image 71: arr = 2.0020971678952284, arr_rep = 2.4876985508354976\n",
      "Processing image 72/513...\n",
      "Image 72: arr = 1.5193101933946715, arr_rep = 1.9973661897573238\n",
      "Processing image 73/513...\n",
      "Image 73: arr = 14.549309968822476, arr_rep = 16.45414786373021\n",
      "Processing image 74/513...\n",
      "Image 74: arr = 2.5737157510694506, arr_rep = 3.2016083359851546\n",
      "Processing image 75/513...\n",
      "Image 75: arr = 2.1912686504251573, arr_rep = 2.9285915865680043\n",
      "Processing image 76/513...\n",
      "Image 76: arr = 3.4314063881010366, arr_rep = 6.935745258385984\n",
      "Processing image 77/513...\n",
      "Image 77: arr = 3.571748508147815, arr_rep = 4.288204041772306\n",
      "Processing image 78/513...\n",
      "Image 78: arr = 2.37686067939122, arr_rep = 3.6142958528794424\n",
      "Processing image 79/513...\n",
      "Image 79: arr = 0.3057910038011345, arr_rep = 0.4423180205809387\n",
      "Processing image 80/513...\n",
      "Image 80: arr = 5.223177667942184, arr_rep = 6.726070584967546\n",
      "Processing image 81/513...\n",
      "Image 81: arr = 1.1747652616947475, arr_rep = 1.1005893087544822\n",
      "Processing image 82/513...\n",
      "Image 82: arr = 7.1853806839589955, arr_rep = 9.587976377931401\n",
      "Processing image 83/513...\n",
      "Image 83: arr = 2.6520466897928907, arr_rep = 3.807862654295689\n",
      "Processing image 84/513...\n",
      "Image 84: arr = 1.386743017007651, arr_rep = 1.4087951755579036\n",
      "Processing image 85/513...\n",
      "Image 85: arr = 3.5724666755607655, arr_rep = 5.267014570460408\n",
      "Processing image 86/513...\n",
      "Image 86: arr = 1.2782634771022396, arr_rep = 1.1632714799888941\n",
      "Processing image 87/513...\n",
      "Image 87: arr = 2.1005570633090445, arr_rep = 2.7018579305573955\n",
      "Processing image 88/513...\n",
      "Image 88: arr = 7.126629835618559, arr_rep = 8.399588241896787\n",
      "Processing image 89/513...\n",
      "Image 89: arr = 3.0671527229548676, arr_rep = 3.6912057161732985\n",
      "Processing image 90/513...\n",
      "Image 90: arr = 1.7133993596965083, arr_rep = 1.6380778605404882\n",
      "Processing image 91/513...\n",
      "Image 91: arr = 4.684402350803791, arr_rep = 5.853282144074765\n",
      "Processing image 92/513...\n",
      "Image 92: arr = 5.365522052596687, arr_rep = 6.6644271680496505\n",
      "Processing image 93/513...\n",
      "Image 93: arr = 3.7636453132035492, arr_rep = 5.180204329138795\n",
      "Processing image 94/513...\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Set paths\n",
    "    base_path = \"./\"\n",
    "    gt_mat_path = os.path.join(base_path, \"NCCdataset\", \"gt.mat\")\n",
    "    # Load ground truth data\n",
    "    gt_data = scipy.io.loadmat(gt_mat_path)\n",
    "    # Use key 'gts' or 'gt' (adjust if necessary)\n",
    "    if \"gts\" in gt_data:\n",
    "        gt = gt_data[\"gts\"]\n",
    "    elif \"gt\" in gt_data:\n",
    "        gt = gt_data[\"gt\"]\n",
    "    else:\n",
    "        gt = None\n",
    "\n",
    "    img_path = os.path.join(base_path, \"NCCdataset\", \"img\")\n",
    "    msk_path = os.path.join(base_path, \"NCCdataset\", \"msk\")\n",
    "    \n",
    "    image_indices = range(1, 514)\n",
    "    Nimg = len(image_indices)\n",
    "    Perf = []\n",
    "    Perf_rep = []\n",
    "    \n",
    "    for i in image_indices:\n",
    "        print(f\"Processing image {i}/{Nimg}...\", flush=True)\n",
    "        imname = f\"{i}.png\"  # In MATLAB: num2str(set(i-set(1)+1)) + '.png'\n",
    "        img_full_path = os.path.join(img_path, imname)\n",
    "        mask_full_path = os.path.join(msk_path, imname)\n",
    "        \n",
    "        # Read image and mask\n",
    "        img = cv2.imread(img_full_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            print(f\"Image not found: {img_full_path}\")\n",
    "            continue\n",
    "        # Convert BGR to RGB and to float64\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float64)\n",
    "        \n",
    "        mask = cv2.imread(mask_full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            print(f\"Mask not found: {mask_full_path}\")\n",
    "            continue\n",
    "        # Convert mask to boolean\n",
    "        mask = mask > 0\n",
    "\n",
    "        img = imresize_nearest(img, 0.25)\n",
    "        mask = imresize_nearest(mask.astype(np.uint8), 0.25).astype(bool)\n",
    "        \n",
    "        # Compute saturation threshold and mask processing\n",
    "        saturation_threshold = np.max(img) * 0.95\n",
    "        # Compute maximum across channels\n",
    "        max_img = np.max(img, axis=2)\n",
    "        # Apply dilation33 to the thresholded image\n",
    "        dilated = dilation33((max_img >= saturation_threshold).astype(np.float64))\n",
    "        mask_im2 = mask.astype(np.float64) + dilated\n",
    "        mask_im2 = (mask_im2 == 0).astype(np.float64)\n",
    "        mask_proc = set_border(mask_im2, 1, method=0)\n",
    "        mask_proc = 1 - mask_proc\n",
    "        \n",
    "        # Parameters for GrayIndexAngular\n",
    "        sigma_val = 0.50\n",
    "        percentage = 1.5\n",
    "        binary_mask = gray_index_angular(img, mask_proc, sigma_val, percentage)\n",
    "        \n",
    "        # Compute saliency map using the updated function\n",
    "        saliencyMap = updated_saliency_map(img, 0.05, 0.30)\n",
    "        a = binary_mask * saliencyMap\n",
    "        \n",
    "        # If 'a' is entirely zero, fallback to binary_mask\n",
    "        if np.count_nonzero(a) == 0:\n",
    "            a = binary_mask\n",
    "        \n",
    "        # Apply the mask 'a' to the image (broadcasting to 3 channels)\n",
    "        img_masked = img * a[:, :, np.newaxis]\n",
    "        \n",
    "        # Set parameters for illuminant estimation\n",
    "        order = 2      # 2nd order derivatives\n",
    "        p = 6          # Minkowski norm\n",
    "        sigma_est = 3  # Gaussian sigma\n",
    "        \n",
    "        illuminant = estimate_illuminant_pixelwise_accelerated(img_masked, order, p, sigma_est, a)\n",
    "        EvaLum = illuminant\n",
    "        \n",
    "        # Compute angular error metrics using angerr2\n",
    "        if gt is not None:\n",
    "            # Adjust for zero-indexing (MATLAB 1-indexing)\n",
    "            gt_val = gt[i - 1, :].flatten()\n",
    "            arr, arr_rep = angerr2(EvaLum, gt_val)\n",
    "            print(f\"Image {i}: arr = {arr}, arr_rep = {arr_rep}\")\n",
    "            Perf.append(arr)\n",
    "            Perf_rep.append(arr_rep)\n",
    "    \n",
    "    # Evaluate performance metrics if any results were collected\n",
    "    if Perf:\n",
    "        mean_perf, median_perf, trimean_perf, bst25, wst25 = evaluate(np.array(Perf))\n",
    "        print(\"Performance (binary errors) [median, mean, trimean, best25%, worst25%]:\", \n",
    "              median_perf, mean_perf, trimean_perf, bst25, wst25)\n",
    "    if Perf_rep:\n",
    "        mean_rep, median_rep, trimean_rep, bst25_rep, wst25_rep = evaluate(np.array(Perf_rep))\n",
    "        print(\"Performance (rep errors) [median, mean, trimean, best25%, worst25%]:\", \n",
    "              median_rep, mean_rep, trimean_rep, bst25_rep, wst25_rep)\n",
    "        \n",
    "    save_arrays_to_single_csv(np.array(Perf), np.array(Perf_rep), filename=\"output.csv\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
